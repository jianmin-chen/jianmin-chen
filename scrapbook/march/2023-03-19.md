## March 19, 2023

I'm starting this documentation of sorts after finding out about [this](https://github.com/cytronicoder/one-year-of-hacking)! I'm just going to document what I learn every day. Specifically, I'm now going to focus a bit more on learning AI and machine learning. I've got a couple of courses I really want to take:

* [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
* [Supervised Machine Learning: Regression and Classification](https://www.coursera.org/learn/machine-learning)
* [Stanford CS321n: Deep Learning for CV](http://cs231n.stanford.edu/index.html)
* [Stanford CS221: Artificial Intelligence - Principles and Techniques](
https://stanford-cs221.github.io/autumn2022/)

Today I started working on the first book.

* Neural networks take a bunch of data -> develop a system that can learn from that data
* Perceptrons = artificial neuron
* A perceptron takes several binary inputs, x1, x2, and produces a single binary output
 
![http://neuralnetworksanddeeplearning.com/images/tikz0.png](http://neuralnetworksanddeeplearning.com/images/tikz0.png)

* In the example shown the perceptron has three inputs
* Frank Rosenblatt, who developed the concept of perceptrons, proposed a simple rule to calculate the output
* Introduced a thing called weights, w1, w2, ..., real numbers expressing the important of the respective inputs to the output
* Neuron's output, 0 or 1, is determined by whether the weighted sum wj * xj is less than or greater than some *threshold value*
* Just like the weights, the threshold is a real number which is a parameter of the neuron. In algebraic terms:
```math
\begin{eqnarray}
\mbox{output} & = & \left\{ \begin{array}{ll}
0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ threshold} \\
1 & \mbox{if } \sum_j w_j x_j > \mbox{ threshold}
\end{array} \right.
\tag{1}\end{eqnarray}
```
 * A way you can think about the perceptron is that it's a device that makes decisions by weighing up evidence
 * Example: Suppose the weekend is coming up, and you've head that there's going to be a cheese festival in your city. You like cheese, and are trying to decide whether or not to go to the festival. You might make your decision by weighing up three factors:
   * Is the weather good? 
   * Does your bf/gf want to accompany yoou?
   * Is the festival near public transit?
   * Represent these with corresponding binary variables x1, x2, x3
   * If the weather is bad, x1 = 0, if weather is good x1 = 1; same for other variables
   * Now suppose you absolutely adore cheese (?), so much so that you're happy to go to the festival even if your bf/gf is uninterested and it's hard to get to. But you really really hate bad weather. You can use weights - w1 = 6, w2 = 2 and w3 = 2 for the other conditions.
   * Finally, you choose a threshold of 5 for the perceptron. That means the resulting value >= 5 for you to go, vs. if you lowered it = more willing to go.
* Obviously not perfect, but imagine having a bunch of these!
* A many-layer network of perceptrons can engage in sophisticated decision making 
* Let's simplify the way we describe perceptrons
* First change is to write it as a dot product (product of matrices) - $w \cdot x \equiv \sum_j w_j x_j$, where w and x are vectors whose components are the weights and inputs, respectively (Remember: vectors are just values with a magnitude and direction)
* Second change is to move the threshold to the other side of the inequality, and replace it with what's known as the perceptron's _bias_, b = -threshold
* Using bias instead of the threshold, we get:
```math
\begin{eqnarray}
  \mbox{output} = \left\{ 
    \begin{array}{ll} 
      0 & \mbox{if } w\cdot x + b \leq 0 \\
      1 & \mbox{if } w\cdot x + b > 0
    \end{array}
  \right.
\tag{2}\end{eqnarray}
```
* You can think of the bias as a measure of how easy it is to get the perceptron to output a 1. Or to put it in more biological terms, how easy it is to get the perceptron to _fire_. 
   * For a perceptron with a really big bias = easy to fire
   * Very negative bias = not so easy
* Another way perceptrons can be used is to compute the elementary logical functions we usually think of as underlying computation, functions like AND, OR, and NAND
* For example, suppose that we have a perceptron with 2 inputs, like so:

![](http://neuralnetworksanddeeplearning.com/images/tikz2.png)

* Input 00 -> output 1, since (-2) * 0 + (-2) * 0 + 3 = 3 is positive. 01 and 10 also = 1. But 11 produces -1! So we have a NAND gate
* We can use perceptrons to compute any logical function
* **It's conventional to draw an extra layer of perceptrons - the input layer - to encode the inputs**
* The notation for input perceptrons, in which we have an output, but no inputs,

![](http://neuralnetworksanddeeplearning.com/images/tikz7.png)

* is a shorthand. It doesn't actually mean we don't have inputs. If that was the case, then the weighted sum would always be zero, and so the perceptron would output 1 if b > 0, and 0 otherwise. That is, it would always output a fixed value, not the desired value.
* Input perceptrons are not really perceptrons, but special units which are simply defined to output the desired values
* We can devise *learning algorithms* which can automatically tune the weights and biases of a network of artificial neurons. This tuning happens in response to external stimuli, not direct intervention

### Sigmoid neurons

* Learning algorithms sound terrific. How can we devise such algorithms for a neural network? 
* Suppose we have a network of perceptrons that we'd like to use to learn to solve some problem. For example, the inputs to a the network might be the raw pixel data from a scanned, handwritten image of a digit. And we'd like the network to learn weights and biases. so that the output from the network correctly classifies the digit.
* To see how learning might work, suppose we make a small change in some weight (or bias) in the network. What we'd like is for this small change in weight to cause only a small corresponding change in the output from the network. As we'll see in a moment, this property will make learning possible. Here's what we might want to do:
![](http://neuralnetworksanddeeplearning.com/images/tikz8.png)
* If it were true that a small change in weight (or bias) causes only a small change in output, then we could use this fact to modify the weights and biases to get our network to behave more in the manner we want. For example, suppose the network keeps classifying 8 as 9. We could figure out how to make a small change in the weights and biases so the network gets close to classifying image as a 9. We'd repeat this, and boom - the network would be learning
* There's a small issue. What if we accidentally change weights or bias of any single neuron in the network that causes the output of that perceptron to flip to 0 to 1? That would completely change the network output
* To get around this, we introduce *sigmoid* neurons. They are similar to perceptrons, but modified so that small changes in their weights and bias cause only a small change in their output.
* We'll depict sigmoid neurons in the same way we depicted perceptrons:
![](http://neuralnetworksanddeeplearning.com/images/tikz9.png)
* Just like a perceptron, it still has inputs. But instead of being zero or one, these inputs can take on any values between 0 and 1
* We also still have weights and an overall bias. However, the output is $\sigma(w \cdot x+b)$, where sigma is called the _sigmoid function_, and is defined by:
```math
\begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}}.
\tag{3}\end{eqnarray}
```
* In other words, the final output is:
```math
\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
\tag{4}\end{eqnarray}
```
* At first sight, sigmoid neurons appear very different to perceptrons, but they are very similar
* To understand the similarity to the perceptron model, suppose z = wx + b is a large positive number. Then $e^{-z} \approx 0$ and so $\sigma(z) \approx 1$. In other words, when the value is large and positive, the output from a sigmoid neuron is basically close to 1. Same thing for when it's negative and large - it's close to 0. It's only when z is of modest size that there's much deviation from the perceptron model
* What about the algebraic form of sigma? It doesn't matter so much as the shape:
![image](https://user-images.githubusercontent.com/59099858/226205247-a91a95ec-330b-4ee0-bfbb-b1df84579dd4.png)
* This shape is a smoothed out version of a step function:
![image](https://user-images.githubusercontent.com/59099858/226205325-d3133627-52a4-421e-9b6c-c2b699531d6f.png)

I also worked a bit on reading [this](https://cs231n.github.io/classification/) article from CS231n on image classification.

* Example: Classifying whether and image is a cat or not
* Many challenges:
   * Viewpoint variation
   * Scale variation
   * Deformation
   * Occlusion
   * Illumination conditions
   * Background clutter
   * Intra-class variation
* Use a data-driven approach such as **Nearest Neighbor Classifier**
* Image classification pipeline:
   * Input: Our input consists of a set of N images, each labeled with one of K different classes. We refer to this data as the training set.
   * Learning: Our task is to use the training set to learn what every one of the classes looks like. We refer to this step as _training a classifier_, or _learning a model_
   * Evaluation: In the end, we evaluate the quality of the classifier by asking it to predict labels for a new set of images it has never seen before. We're hoping that a lot of predictions match up with actual answers (_ground truth_)

### Nearest Neighbor Classifier

* Example dataset: One popular toy image dataset is the CIFAR-10 dataset, consisting of 60,000 tiny images labeled in 10 categories
* Suppose we're given this dataset. The nearest neighbor will take a test image, compare it to every single one of the training images, and predict the label of the closest training image.
* How can we go about comparing two images? Well, two images are just two blocks of 32 x 32 x 3. One easy way is to compare the images pixel by pixel and add up the differences. In other words, given two images and representing them as vectors I1, I2, a reasonable choice for comparing them might be the L1 distance:
```math
d_1 (I_1, I_2) = \sum_{p} \left| I^p_1 - I^p_2 \right|
```
![](https://cs231n.github.io/assets/nneg.jpeg)
* First, let's load the CIFAR-10 data into memory as 4 arrays:
   * The training data/labels and the test data/labels
   * Then set up a nearest neighbor classifier. Here's the initial example:
```python
import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in range(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
```
* This code only achieves 38.6% accuracy on CIFAR-10
* There are several ways we can improve this:
    * The choice of distance. There are many ways of computing distances between vectors. Another common choice could be to instead use the L2 distance, which ~~has the geometric interpretation of computing the euclidean distance between two vectors~~ basically is the Pythagorean theorem, like so:
```math
d_2 (I_1, I_2) = \sqrt{\sum_{p} \left( I^p_1 - I^p_2 \right)^2}
```
    * In other words we would be squaring all of them, adding them up and then taking the square root.

### k-Nearest Neighbor Classifier

* Another way we can improve this is not by just taking the label of the nearest image, but by taking the average of the k nearest neighbors.
* Intuitively, higher values of k have a smoothing effect that makes the classifier more resistance to outliers.
* What numbers works best?
* Additionally, many different distance functions we could have used
* These choices are called **hyperparameters**
* You might be tempted to try out many different values and see what works best, but you **cannot use the test set for determining hyperparameters**. 
* Otherwise, the very real danger is that you may tune your hyperparameters to fit the test set, but not on others - in other words, you **overfit** the test set
* On the other hand, if you use the test set once at the end, it remains a good proxy for measuring the generalization of your classifier
* There is a correct way of tuning the hyperparameters: split our training set in two: a slightly smaller training set, and what we call a validation set. Using CIFAR-10 as an example, we can use 49,000 for training, and 1,000 aside for validation - aka a fake test set
* In cases where the size of your training data (and therefore the validation data) might be small, people sometimes use a more sophisticated technique for hyperparameter tuning called **cross-validation**. Basically, instead of arbitrarily picking the first 1000 datapoints to be the validation set, you can get a better and less noisy estimate by iterating over different different sets and averaging performance across each.
* For example, in 5-fold cross-validation, we could use 4 for training, 1 for validation. We then iterate over each training set as validation set, and average the performance
* In practice, people tend to avoid cross-validation since it's computationally expensive

### Pros and Cons of Nearest Neighbor

* Not very practical for "high-dimensional objects"
* For example, using a visualization technique called t-SNE (I've seen this term so much), the result is:

![](https://cs231n.github.io/assets/pixels_embed_cifar10.jpg)

* Notice that frog and dog are next to each other because they're on a white background

### Gradient-based learning

I know. So much notes for my first day! Unfortuanately, Sunday's my only day to really focus in depth on learning material, so here we go!

* **Supervised learning** is the process of using truth data to iteratively improve the performance of a model that is performing a task
* How does a model learn?
* In general, a machine learning model will use mathematical operations to map its input data to an abstract representation (a numerical encoding of the data) that is useful for the machine learning task at hand. 
* For image classification using a neural network (using the image classification in CS231n), the input pixels of an image are ultimately mapped to a vector of values that represents, say, how "dog-like", "cat-like", "truck-like", or "boat-like"
* In the context of neural networks, this mathematical mapping is referred to as a **forward pass**. The model uses numerical parameters to perform this mapping
* How can a model arrive at "good" values for its numerical parameters? This is where **supervised learning** comes into play. In supervised learning, labeled data (also referred to as truth data) is available so that the model can compare its prediction to the correct answer, and adjust its numerical parameters (hehe, weights) to the correct answer
* KNN was an example of a semi-supervised classification scheme, but did not lead to any refinement
* **Unsupervised learning** involves finding patterns in data without reference to any labels, achieved with statistical analysis
* A critical aspect to supervised learning is the formulation of a **loss (aka objective) function**. This is a mathematical function that provides a good measure of how well a model does its job when its predictions are checked against truth data.
* The model is therefore trained by updating its parameters so that it reduces the output of the loss function the next time it makes a prediction (i.e. performs a **forward pass**) on a given piece of training data
* Once we have a good loss function, the supervised learning process is as follows:
    * Have the model make its predictions (i.e. perform a forward pass) on the training data

### Extra notes for today

* Found out that `__init__.py` is super useful for setting up a Python module/package!
